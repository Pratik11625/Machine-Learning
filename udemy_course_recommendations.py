# -*- coding: utf-8 -*-
"""Udemy_course_recommendations.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d3bMpPFsrOxYRl2dELsjg3T0yaTPflAy
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install neattext
from warnings import filterwarnings
filterwarnings('ignore')
import pandas as pd
import numpy as np
import neattext.functions as nfx
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity,linear_kernel

df = pd.read_csv('/content/udemy_course_data.csv')
df.head()

df.shape

df.info()

df.describe(include='all')

df.isnull().sum()

df.corr()

plt.figure(figsize=(10, 8))
ip=df['is_paid'].value_counts()
labels={True:'Is paid',
  False:'not paid'}
ip.index=ip.index.map(labels)
colors = ['skyblue', 'lightcoral']

plt.pie(ip,labels=ip.index, autopct='%1.1f%%', colors=colors)

plt.show()

plt.figure(figsize=(10, 8))
plt.pie(df['subject'].value_counts(), labels=df['subject'].value_counts().index, autopct='%.2f%%')
plt.title('Distribution of Subjects')
plt.show()

plt.figure(figsize=(14, 7))
df.groupby(['subject', 'level']).size().unstack().plot(kind='bar', stacked=True)

plt.title('Count of Levels by Subject Category', fontsize=18, fontweight='bold', color='blue')
plt.xlabel('Subject Category', fontsize=16, fontweight='bold', color='orange')
plt.ylabel('Count of Levels', fontsize=16, fontweight='bold', color='orange')
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.legend(title='Level', fontsize=12, title_fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()

plt.figure(figsize=(14,7))
df.groupby(['subject'])['level'].value_counts().plot(kind = 'bar')

plt.xticks(fontsize = 16)
plt.yticks(fontsize = 16)
plt.xlabel('Subject Category',fontsize = 16,fontweight = 'bold',color = 'orange')
plt.ylabel('Count of Levels',fontsize = 16,fontweight = 'bold',color = 'orange')

# plt.figure(figsize=(12,7))
# sns.barplot(x='level',y='num_subscribers', hue='subject',data=df)
# plt.xticks(fontsize = 16)
# plt.yticks(fontsize = 16)
# plt.xlabel('Level',fontsize = 16,fontweight = 'bold',
#            color = 'orange')
# plt.ylabel('Subscribers Count',fontsize = 16,fontweight = 'bold',
#            color = 'orange')
# plt.xticks(rotation = 'vertical')
# plt.show()

plt.figure(figsize=(14, 7))
sns.barplot(x='level', y='num_subscribers', hue='subject', data=df)

plt.title('Number of Subscribers by Level and Subject Category', fontsize=18, fontweight='bold', color='blue')
plt.xlabel('Level', fontsize=16, fontweight='bold', color='orange')
plt.ylabel('Subscribers Count', fontsize=16, fontweight='bold', color='orange')
plt.xticks(fontsize=14, rotation='vertical')
plt.yticks(fontsize=14)
plt.legend(title='Subject', fontsize=12, title_fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()

# plt.figure(figsize=(14, 7))
# ax = sns.barplot(data=df, y='subject', x='price', order=df.sort_values('price').subject, palette='viridis')

# plt.xlabel('Total Price', fontsize=14, fontweight='bold', color='orange')
# plt.ylabel('Subject', fontsize=14, fontweight='bold', color='orange')
# plt.title('Total Price per Subject', fontsize=16, fontweight='bold', color='blue')

# plt.xticks(fontsize=12)
# plt.yticks(fontsize=12)

# plt.grid(axis='x', linestyle='--', alpha=0.7)

# plt.show()

df[df['profit']==df['profit'].min()].style.background_gradient(cmap = 'plasma')



"""Generating clean text by removing the stopwords and special characters"""

df['Clean_title'] = df['course_title'].apply(nfx.remove_stopwords)

df['Clean_title'] = df['Clean_title'].apply(nfx.remove_special_characters)

df['Clean_title'].iloc[1:5]



"""# vectorizing the course_title"""

countvect = CountVectorizer()
cv = countvect.fit_transform(df['Clean_title'])
cv

df_cv_words = pd.DataFrame(cv.todense(),columns=countvect.get_feature_names_out())
df_cv_words.head()



"""# cosine similarity matrix"""

cosine_sim_mat = cosine_similarity(cv)
cosine_sim_mat



"""# drop duplicates"""

course_index = pd.Series(df.index,index = df['course_title']).drop_duplicates()



temp = df[df['course_title'].str.contains('Python')]
temp.head()

top6 = temp.sort_values(by = 'num_subscribers',ascending=False)
top6.head()



"""Test keyword"""

index = course_index['How To Maximize Your Profits Trading Options'] # example

scores = list(enumerate(cosine_sim_mat[index]))

sorted_score = sorted(scores,key = lambda x:x[1],reverse=True)
sorted_score[7]

# selected coures indices
selected_course_indices=[i[0] for i in sorted_score[1:]]

selected_course_indices[5]

sorted_values = [i[1] for i in sorted_score[1:]]
sorted_values[7]



recommended_result_df = df.iloc[selected_course_indices]
recommended_result_df.head()

recommended_result_df['Similarity_Score'] = np.array(sorted_values)
recommended_result_df.head()

use_df = recommended_result_df[['Clean_title','Similarity_Score']]
use_df



# def recommend_course(keyword, numrec):

#     course_index = pd.Series(
#         df.index, index=df['course_title']).drop_duplicates()

#     index = course_index[keyword]

#     scores = list(enumerate(cosine_sim_mat [index]))

#     sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)

#     selected_course_index = [i[0] for i in sorted_scores[1:]]

#     selected_course_score = [i[1] for i in sorted_scores[1:]]

#     rec_df = df.iloc[selected_course_index]

#     rec_df['Similarity_Score'] = selected_course_score

#     final_recommended_courses = rec_df[[
#         'course_title', 'url', 'price', 'num_subscribers']]

#     return final_recommended_courses.head(numrec)



def recommend_course(keyword, numrec):
    # Validate keyword existence
    if keyword not in df['course_title'].values:
        return "Keyword not found in course titles."

    # Validate numrec
    if not isinstance(numrec, int) or numrec <= 0:
        return "Invalid number of recommendations. Please provide a positive integer."

    # Create course index
    course_index = pd.Series(df.index, index=df['course_title']).drop_duplicates()

    # Get index of keyword
    index = course_index[keyword]

    # Get cosine similarity scores
    scores = list(enumerate(cosine_sim_mat[index]))

    # Sort scores
    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)

    # Get recommended course indices and scores
    selected_course_index = [i[0] for i in sorted_scores[1:numrec+1]]
    selected_course_score = [i[1] for i in sorted_scores[1:numrec+1]]

    # Create DataFrame of recommended courses
    rec_df = df.iloc[selected_course_index]
    rec_df['Similarity_Score'] = selected_course_score

    # Select relevant columns
    final_recommended_courses = rec_df[['course_title', 'url', 'price', 'num_subscribers', 'Similarity_Score']]

    # Return recommended courses
    return final_recommended_courses



recommended_courses = recommend_course("How To Maximize Your Profits Trading Options", 5)
recommended_courses

